{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d0d6f394-9b19-4fa7-8753-a0145cf653ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchvision\n",
    "import torchvision.datasets as MNIST\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "USE_CUDA = torch.cuda.is_available()\n",
    "DEVICE = torch.device(\"cuda:0\" if USE_CUDA else 'cpu')\n",
    "print(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4ddfda03-2e95-48ab-afb8-736fb7f96a16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jovyan/졸업작품/UNLV_Project'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39033b65-db73-4170-a0d5-269cfb741149",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data shape is (949, 785), test data shape is (50, 785)\n",
      "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
      "0      0       0       0       0       0       0       0       0       0   \n",
      "1      0       0       0       0       0       0       0       0       0   \n",
      "2      0       0       0       0       0       0       0       0       0   \n",
      "3      0       0       0       0       0       0       0       0       0   \n",
      "4      0       0       0       0       0       0       0       0       0   \n",
      "\n",
      "   pixel8  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
      "0       0  ...         0         0         0         0         0         0   \n",
      "1       0  ...         0         0         0         0         0         0   \n",
      "2       0  ...         0         0         0         0         0         0   \n",
      "3       0  ...         0         0         0         0         0         0   \n",
      "4       0  ...         0         0         0         0         0         0   \n",
      "\n",
      "   pixel780  pixel781  pixel782  pixel783  \n",
      "0         0         0         0         0  \n",
      "1         0         0         0         0  \n",
      "2         0         0         0         0  \n",
      "3         0         0         0         0  \n",
      "4         0         0         0         0  \n",
      "\n",
      "[5 rows x 785 columns]\n"
     ]
    }
   ],
   "source": [
    "train_path = \"Dataset/MNIST_training.csv\"\n",
    "test_path = \"Dataset/MNIST_test.csv\"\n",
    "\n",
    "train = pd.read_csv(train_path)\n",
    "test = pd.read_csv(test_path)\n",
    "\n",
    "print(f\"train data shape is {train.shape}, test data shape is {test.shape}\")\n",
    "print(test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "49658c2b-8c05-4a38-9af9-98bc7b6ff6a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 images processed.\n",
      "100 images processed.\n",
      "200 images processed.\n",
      "300 images processed.\n",
      "400 images processed.\n",
      "500 images processed.\n",
      "600 images processed.\n",
      "700 images processed.\n",
      "800 images processed.\n",
      "900 images processed.\n",
      "0 images processed.\n"
     ]
    }
   ],
   "source": [
    "train_y = train[[\"label\"]]\n",
    "train_x = train.drop(columns = \"label\")\n",
    "\n",
    "test_y = test[[\"label\"]]\n",
    "test_x = test.drop(columns = \"label\")\n",
    "\n",
    "##pixel -> image, 각각의 열마다 이미지를 만들어주기, MNIST 이미지가 28에서 끊어주기.\n",
    "\n",
    "##Train data\n",
    "os.makedirs(\"Dataset/train_images\", exist_ok=True)\n",
    "for idx in range(len(train_x)):\n",
    "    image = train_x.iloc[idx].values.reshape(28,28)\n",
    "    plt.imsave(f\"Dataset/train_images/image_{idx:03d}.png\", image, cmap='gray')\n",
    "    if idx % 100 == 0: \n",
    "        print(f\"{idx} images processed.\")\n",
    "        \n",
    "##test Data\n",
    "os.makedirs(\"Dataset/test_images\", exist_ok=True)\n",
    "\n",
    "for idx in range(len(test_x)):\n",
    "    image = test_x.iloc[idx].values.reshape(28,28)\n",
    "    plt.imsave(f\"Dataset/test_images/image_{idx:03d}.png\", image, cmap='gray')    \n",
    "    if idx % 100 == 0:  \n",
    "        print(f\"{idx} images processed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c641befb-50c8-4ea8-b2af-e55e5340aa51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforms\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.ToTensor(),  # Convert PIL Image to Tensor\n",
    "    transforms.Normalize((0.5,), (0.5,))  # Normalize: mean=0.5, std=0.5\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "906a5961-d3cc-4952-9a99-91efb4d9f2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, images_dir, labels, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            images_dir (str): Directory containing the images.\n",
    "            labels (pd.DataFrame): DataFrame containing the labels.\n",
    "            transform (callable, optional): Optional transforms to be applied on an image.\n",
    "        \"\"\"\n",
    "        self.images_dir = images_dir\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "        self.image_files = sorted(os.listdir(images_dir))  # Ensure consistent order\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Load image\n",
    "        image_path = os.path.join(self.images_dir, f\"image_{idx:03d}.png\")\n",
    "        image = Image.open(image_path).convert(\"L\")  # Convert to grayscale\n",
    "\n",
    "        # Apply transforms\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        # Get label\n",
    "        label = self.labels.iloc[idx].values[0]  # Assuming labels are in DataFrame\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ae19e878-42c2-4d17-906a-d728a9d561c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "train_images_dir = \"Dataset/train_images\"\n",
    "test_images_dir = \"Dataset/test_images\"\n",
    "\n",
    "train_labels = pd.read_csv(\"Dataset/MNIST_training.csv\")[[\"label\"]]\n",
    "test_labels = pd.read_csv(\"Dataset/MNIST_test.csv\")[[\"label\"]]\n",
    "\n",
    "# Dataset and DataLoader\n",
    "train_dataset = MyDataset(images_dir=train_images_dir, labels=train_labels, transform=transform)\n",
    "test_dataset = MyDataset(images_dir=test_images_dir, labels=test_labels, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2e9e2846-db74-408c-bb98-d0c4c6442f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1, downsample=None):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(out_channels)\n",
    "        )\n",
    "        self.downsample = downsample\n",
    "        self.relu = nn.ReLU()\n",
    "        self.out_channels = out_channels\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        # Apply convolution layers\n",
    "        out = self.conv1(x)\n",
    "        out = self.conv2(out)\n",
    "\n",
    "        # Downsample residual if necessary\n",
    "        if self.downsample:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        # Add residual and apply activation\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "77212935-4ad9-48c4-b7bb-e7cd7a5406d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, layers, num_classes = 10):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.inplanes = 64\n",
    "        self.conv1 = nn.Sequential(nn.Conv2d(1, 64, kernel_size = 7, stride = 2, padding = 3),\n",
    "                                  nn.BatchNorm2d(64),\n",
    "                                  nn.ReLU())\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size = 3, stride = 2, padding = 1)\n",
    "        self.layer0 = self._make_layer(block, 64, layers[0], stride = 1)\n",
    "        self.layer1 = self._make_layer(block, 128, layers[1], stride = 2)\n",
    "        self.layer2 = self._make_layer(block, 256, layers[2], stride = 2)\n",
    "        self.layer3 = self._make_layer(block, 512, layers[3], stride = 2)\n",
    "        self.avgpool = nn.AvgPool2d(7, stride = 1)\n",
    "        self.fc = nn.Linear(512, num_classes)\n",
    "        \n",
    "    def _make_layer(self, block, planes, blocks, stride=1):\n",
    "        downsample = None\n",
    "\n",
    "        # Downsample if stride > 1 or channels don't match\n",
    "        if stride != 1 or self.inplanes != planes:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.inplanes, planes, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(planes),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
    "        self.inplanes = planes\n",
    "\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.layer0(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        \n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0),-1)\n",
    "        x = self.fc(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0cdccd4b-d3b9-43c9-adb6-28d994055f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 10\n",
    "epochs = 20\n",
    "batch_size = 16\n",
    "learning_rate = 0.01\n",
    "\n",
    "model = ResNet(ResidualBlock, [2, 2, 2, 2], num_classes=10).to(DEVICE)\n",
    "\n",
    "##Loss and Optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = learning_rate, weight_decay = 0.001, momentum = 0.9)\n",
    "\n",
    "total_step = len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7ed8be19-94b2-45b6-8630-d95c9bd8007f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Loss: 0.0033\n",
      "Accuracy of the network on the 50 test images 94.0 %\n",
      "Epoch [2/20], Loss: 0.0006\n",
      "Accuracy of the network on the 50 test images 94.0 %\n",
      "Epoch [3/20], Loss: 0.0217\n",
      "Accuracy of the network on the 50 test images 94.0 %\n",
      "Epoch [4/20], Loss: 0.1177\n",
      "Accuracy of the network on the 50 test images 92.0 %\n",
      "Epoch [5/20], Loss: 0.0003\n",
      "Accuracy of the network on the 50 test images 96.0 %\n",
      "Epoch [6/20], Loss: 0.0055\n",
      "Accuracy of the network on the 50 test images 98.0 %\n",
      "Epoch [7/20], Loss: 0.0038\n",
      "Accuracy of the network on the 50 test images 94.0 %\n",
      "Epoch [8/20], Loss: 0.0010\n",
      "Accuracy of the network on the 50 test images 96.0 %\n",
      "Epoch [9/20], Loss: 0.0002\n",
      "Accuracy of the network on the 50 test images 98.0 %\n",
      "Epoch [10/20], Loss: 0.0065\n",
      "Accuracy of the network on the 50 test images 96.0 %\n",
      "Epoch [11/20], Loss: 0.0007\n",
      "Accuracy of the network on the 50 test images 98.0 %\n",
      "Epoch [12/20], Loss: 0.0113\n",
      "Accuracy of the network on the 50 test images 94.0 %\n",
      "Epoch [13/20], Loss: 0.0008\n",
      "Accuracy of the network on the 50 test images 94.0 %\n",
      "Epoch [14/20], Loss: 0.0022\n",
      "Accuracy of the network on the 50 test images 94.0 %\n",
      "Epoch [15/20], Loss: 0.0019\n",
      "Accuracy of the network on the 50 test images 94.0 %\n",
      "Epoch [16/20], Loss: 0.0043\n",
      "Accuracy of the network on the 50 test images 94.0 %\n",
      "Epoch [17/20], Loss: 0.0885\n",
      "Accuracy of the network on the 50 test images 94.0 %\n",
      "Epoch [18/20], Loss: 0.2600\n",
      "Accuracy of the network on the 50 test images 94.0 %\n",
      "Epoch [19/20], Loss: 0.0402\n",
      "Accuracy of the network on the 50 test images 88.0 %\n",
      "Epoch [20/20], Loss: 0.0019\n",
      "Accuracy of the network on the 50 test images 94.0 %\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    for i,(images, labels) in enumerate(train_loader):\n",
    "        images = images.to(DEVICE)\n",
    "        labels = labels.to(DEVICE)\n",
    "        \n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print ('Epoch [{}/{}], Loss: {:.4f}' .format(epoch+1, epochs, loss.item()))\n",
    "    \n",
    "    ##test\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for images, labels in test_loader:\n",
    "            images = images.to(DEVICE)\n",
    "            labels = labels.to(DEVICE)\n",
    "            outputs = model(images)\n",
    "            \n",
    "            _,predicted = torch.max(outputs.data,1)\n",
    "            total+=labels.size(0)\n",
    "            correct += (predicted==labels).sum().item()\n",
    "        print(\"Accuracy of the network on the {} test images {} %\".format(50, 100*correct/total))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
